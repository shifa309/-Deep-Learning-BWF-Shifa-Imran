{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd3846ef",
   "metadata": {},
   "source": [
    "# Stacking up layers in NN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f828b549",
   "metadata": {},
   "source": [
    "Stacking up layers in a neural network refers to the process of adding multiple layers on top of each other to create a deep neural network. This is commonly referred to as deep learning. Each layer in a neural network is composed of multiple neurons, and the layers are connected to each other through weights.\n",
    "\n",
    "The process of stacking layers is straightforward. You start with an input layer that receives the input data. Then, you add one or more hidden layers between the input and output layers. The hidden layers are responsible for learning complex representations of the input data. Finally, you add an output layer that produces the final output of the network.\n",
    "\n",
    "Each layer in a neural network typically has multiple neurons. Neurons in one layer are connected to neurons in the next layer through weighted connections. These weights are adjusted during the training process to optimize the network's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6e0e35",
   "metadata": {},
   "source": [
    "#  Artificial Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f742afdd",
   "metadata": {},
   "source": [
    "ANN stands for Artificial Neural Network. \n",
    "An artificial neural network consists of interconnected nodes, called artificial neurons or units, organized in layers. Typically, an ANN comprises an input layer, one or more hidden layers, and an output layer. Each neuron in a layer receives input signals, performs a computation, and passes the output to the next layer.\n",
    "\n",
    "The basic building block of an artificial neuron is a mathematical function that takes weighted inputs, applies an activation function, and produces an output. The weights associated with the inputs determine the importance or strength of each input signal. The activation function introduces non-linearity into the model, allowing neural networks to learn complex patterns and relationships.\n",
    "\n",
    "As discussed in Tsk 26;, During the training process, the weights of the connections between neurons are adjusted iteratively based on a given learning algorithm. The goal is to minimize the difference between the predicted outputs of the network and the desired outputs, which is known as the loss or cost function. This process, called backpropagation, involves propagating the error from the output layer back through the network, adjusting the weights to improve the network's performance, by finding partial derivatives with respect to each weights and biases involved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc07a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "# Create a sequential model\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "# Add the first hidden layer\n",
    "model.add(keras.layers.Dense(units=64, activation='relu', input_shape=(input_dim,)))\n",
    "\n",
    "# Add additional hidden layers\n",
    "model.add(keras.layers.Dense(units=128, activation='relu'))\n",
    "model.add(keras.layers.Dense(units=256, activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(keras.layers.Dense(units=num_classes, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4f1c34",
   "metadata": {},
   "source": [
    "In the above code:\n",
    "The number of units in the output layer depends on the specific task. For example, in a classification task with three classes, num_classes would be set to 3, and the activation function would typically be softmax.\n",
    "\n",
    "By stacking layers in this manner, we create a deep neural network capable of learning complex representations from the input data. The output of each layer becomes the input to the next layer, enabling the network to extract higher-level features and make more sophisticated predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f233c258",
   "metadata": {},
   "source": [
    "# How to choose - How many hidden layers must be there and how many neurons in each layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7981d60a",
   "metadata": {},
   "source": [
    "There is no fixed rule or formula to determine the optimal architecture, as it depends on various factors, including the complexity of the problem, the amount of available data, and the computational resources at hand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f245abef",
   "metadata": {},
   "source": [
    "# EXAMPLE - XOR Gate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe78265b",
   "metadata": {},
   "source": [
    "The XOR gate is a logical operation that takes two binary inputs and returns 1 (True) only if exactly one of the inputs is 1. Otherwise, it returns 0 (False).\n",
    "\n",
    "Considering a scenario where we want to train a neural network to mimic the behavior of the XOR gate. The XOR gate is not a linearly separable problem, meaning a single-layered network (with only an input and output layer) cannot accurately represent it. However, by adding a hidden layer, we can enable the neural network to learn and represent the XOR gate's behavior.\n",
    "\n",
    "In this case, the input layer will have two neurons (one for each input), and the output layer will have one neuron (for the output). We introduce a hidden layer in between, which can have varying numbers of neurons.\n",
    "\n",
    "With a single hidden layer, the neural network can learn non-linear combinations of the input features. For the XOR gate, the hidden layer's neurons will allow the network to capture the exclusive OR relationship. The hidden layer acts as a feature extractor, transforming the input representation into a higher-dimensional space where the XOR operation becomes linearly separable.\n",
    "\n",
    "For the XOR gate problem, a neural network with one hidden layer containing two neurons should be sufficient. Here's an example architecture. but it depends and varies according to the real world problem at hand."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
